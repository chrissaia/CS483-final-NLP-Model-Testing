# CS483 Final Project: NLP Model Testing with LIME and SHAP

## Overview

This repository contains code and data for a CS483 final project exploring the use of **LIME** (Local Interpretable Model‑agnostic Explanations) and **SHAP** (SHapley Additive exPlanations) to test a sentiment‑analysis model.  The goal is to better understand how a pre‑trained DistilBERT model makes predictions and to evaluate its behaviour under negation, sarcasm, spelling noise and fairness scenarios.  By combining model‑explainability tools with robustness tests we obtain actionable insights about the model’s strengths and weaknesses.

## Dataset

The project uses the [Sentiment Analysis for Financial News](https://www.kaggle.com/ankurzing/sentiment-analysis-for-financial-news) dataset.  The code downloads the latest version via `kagglehub.dataset_download` and reads the data into `all-data.csv`:contentReference[oaicite:0]{index=0}.  Each record contains a piece of financial news text and a sentiment label (positive, negative or neutral).  Neutral entries are dropped so that the model learns to classify only positive and negative sentiments:contentReference[oaicite:1]{index=1}.  A small sample of the dataset is shown in `model_lime_test.ipynb`, where the first few rows illustrate the text and sentiment columns.

## Repository Structure

- **`lime_tests/`** – Directory containing the Jupyter notebooks used for experiments.
  - **`all-predictions.ipynb`** – Loads a pre‑trained DistilBERT sentiment model and computes predictions and classification metrics on the dataset.
  - **`model_lime_test.ipynb`** – Demonstrates how to prepare the dataset and use `LimeTextExplainer` to interpret individual predictions; includes the dataset download and filtering logic:contentReference[oaicite:2]{index=2}.
  - **`robust_testing.ipynb`** – Conducts a series of robustness and fairness tests using LIME.  The notebook examines negation handling, emotional word weighting, sarcasm, gender fairness, adversarial misspellings and mixed‑sentiment clauses, and aggregates global word importance across all tests:contentReference[oaicite:3]{index=3}.
- **`all-data.csv`** – The dataset after filtering to positive/negative entries.
- **`lime_explanation.html`** – Example interactive HTML file generated by LIME; open in a browser to inspect word‑level explanations.
- **`requirements.txt`** – Lists Python dependencies including PyTorch, transformers, pandas, scikit‑learn, matplotlib, shap and lime.

## Installation and Setup

1. Clone this repository and navigate into it.  Ensure you have Python 3.11 installed.
2. Create and activate a virtual environment if desired.
3. Install dependencies:

```bash
pip install -r requirements.txt

